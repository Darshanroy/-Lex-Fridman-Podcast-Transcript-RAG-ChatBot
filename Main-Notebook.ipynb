{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-huggingface\n",
    "# !pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader,UnstructuredCSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.chains import HypotheticalDocumentEmbedder\n",
    "from langchain_chroma import Chroma\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']= os.environ['HUGGINGFACEHUB_API_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_embeddings = HuggingFaceEndpointEmbeddings(\n",
    "    model= \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    task=\"feature-extraction\",\n",
    "    huggingfacehub_api_token=os.environ['HUGGINGFACEHUB_API_TOKEN'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\91845\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\91845\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\91845\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\91845\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Llama3LLM = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=1000,\n",
    "    do_sample=False,\n",
    ")\n",
    "Llama3LLMHydeEmbeddings = HypotheticalDocumentEmbedder.from_llm(Llama3LLM,\n",
    "                                                  hf_embeddings,\n",
    "                                                  prompt_key = \"web_search\")\n",
    "\n",
    "\n",
    "MistralLLM = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=1000,\n",
    "    do_sample=False,\n",
    ")\n",
    "MistralLLMHydeEmbeddings = HypotheticalDocumentEmbedder.from_llm(MistralLLM,\n",
    "                                                  hf_embeddings,\n",
    "                                                  prompt_key = \"web_search\")\n",
    "\n",
    "\n",
    "GemmaLLM = HuggingFaceEndpoint(\n",
    "    repo_id=\"google/gemma-7b\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=1000,\n",
    "    do_sample=False,\n",
    ")\n",
    "GemmaLLMHydeEmbeddings = HypotheticalDocumentEmbedder.from_llm(GemmaLLM,\n",
    "                                                  hf_embeddings,\n",
    "                                                  prompt_key = \"web_search\")\n",
    "\n",
    "Llama2LLM = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-2-7b-hf\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=1000,\n",
    "    do_sample=False,\n",
    ")\n",
    "Llama2LLMHydeEmbeddings = HypotheticalDocumentEmbedder.from_llm(Llama2LLM,\n",
    "                                                  hf_embeddings,\n",
    "                                                  prompt_key = \"web_search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredCSVLoader(r\"docs\\Lex\\podcastdata_dataset.csv\")\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=20)\n",
    "text_splitter.split_documents(docs)\n",
    "documents=text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Design ChatPrompt Template\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "just give main Answer the following question based only on the provided context. \n",
    "Think step by step before providing a detailed answer. \n",
    "I will tip you $1000 if the user finds the answer helpful. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "Question: {input}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Llama2LLMDB=Chroma.from_documents(documents[:10000],Llama2LLMHydeEmbeddings)\n",
    "Llama3LLMDB=Chroma.from_documents(documents[:10000],Llama3LLMHydeEmbeddings)\n",
    "MistralLLMDB = Chroma.from_documents(documents[:10000],MistralLLMHydeEmbeddings)\n",
    "GemmaLLMDb=Chroma.from_documents(documents[:10000],GemmaLLMHydeEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Llama2LLMRetriever = Llama2LLMDB.as_retriever(type=\"similarity\")\n",
    "Llama3LLMRetriever = Llama3LLMDB.as_retriever(type=\"similarity\")\n",
    "MistralLLMRetriever = MistralLLMDB.as_retriever(type=\"similarity\")\n",
    "GemmaLLMRetriever = GemmaLLMDb.as_retriever(type=\"similarity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Stuff Docment Chain for Llama3\n",
    "DocumentChainLlama3LLM = create_stuff_documents_chain(Llama3LLM,prompt)\n",
    "RetrievalChainLlama3LLM = create_retrieval_chain(Llama3LLMRetriever,DocumentChainLlama3LLM)\n",
    "\n",
    "## Create Stuff Docment Chain for Llama2\n",
    "DocumentChainLlama2LLM = create_stuff_documents_chain(Llama2LLM,prompt)\n",
    "RetrievalChainLlama2LLM = create_retrieval_chain(Llama2LLMRetriever,DocumentChainLlama2LLM)\n",
    "\n",
    "\n",
    "# ## Create Stuff Docment Chain for Gemma\n",
    "DocumentChainGemmaLLM = create_stuff_documents_chain(GemmaLLM,prompt)\n",
    "RetrievalChainGemmaLLM = create_retrieval_chain(GemmaLLMRetriever,DocumentChainGemmaLLM)\n",
    "\n",
    "\n",
    "## Create Stuff Docment Chain for mistral\n",
    "DocumentChainMistralLLM = create_stuff_documents_chain(MistralLLM,prompt)\n",
    "RetrievalChainMistralLLM = create_retrieval_chain(MistralLLMRetriever,DocumentChainMistralLLM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    MistralOutput = RetrievalChainMistralLLM.invoke({\"input\":\"How does Lex Fridman approach philosophical questions in his discussions?\"})\n",
    "    # Llama2Output = RetrievalChainLlama2LLM.invoke({\"input\":\"How does Lex Fridman approach philosophical questions in his discussions?\"})\n",
    "    GemmaOutput = RetrievalChainGemmaLLM.invoke({\"input\":\"How does Lex Fridman approach philosophical questions in his discussions?\"})\n",
    "    Llama3Output = RetrievalChainLlama3LLM.invoke({\"input\":\"How does Lex Fridman approach philosophical questions in his discussions?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(MistralOutput['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing diffrent LLMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This chain was only tested with GPT-4. Performance may be significantly worse with other models.\n"
     ]
    }
   ],
   "source": [
    "from langchain.evaluation import load_evaluator\n",
    "\n",
    "\n",
    "custom_criteria = {\n",
    "    \"simplicity\": \"Is the language straightforward and unpretentious?\",\n",
    "    \"clarity\": \"Are the sentences clear and easy to understand?\",\n",
    "    \"precision\": \"Is the writing precise, with no unnecessary words or details?\",\n",
    "    \"truthfulness\": \"Does the writing feel honest and sincere?\",\n",
    "    \"subtext\": \"Does the writing suggest deeper meanings or themes?\",\n",
    "}\n",
    "evaluator = load_evaluator(\"pairwise_string\", criteria=custom_criteria, llm=MistralLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "\"What does Lex Fridman discuss about the ethical implications of AI?\",\n",
    "\"What insights are shared on human-robot interaction?\",\n",
    "\"What are some technological innovations mentioned in the podcast?\",\n",
    "\"How does Lex Fridman approach philosophical questions in his discussions?\",\n",
    "\"What expertise do guests like Elon Musk bring to the podcast?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': '\\n\\nEvaluation:\\n- Simplicity: Both assistants use simple language.\\n- Clarity: Both assistants provide clear answers.\\n- Precision: Both assistants are precise.\\n- Truthfulness: Both assistants answer truthfully.\\n- Subtext: Assistant B suggests a step-by-step approach that Lex Fridman follows to discuss philosophical questions.\\n\\nVerdict: [[B]] Assistant B provides a more detailed explanation of how Lex Fridman approaches philosophical questions.',\n",
       " 'value': 'B',\n",
       " 'score': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_string_pairs(\n",
    "    prediction=f\"{MistralOutput['answer']}\",\n",
    "    prediction_b=f\"{GemmaOutput['answer']}\",\n",
    "    input={questions[0]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reasoning': \"\\n\\nEvaluation:\\nAssistant A's response is clear, concise, and focused on the question asked by the user. It provides a direct answer without any unnecessary details, making it easy for the user to understand. Assistant A's response is also truthful and sincere, as it accurately describes Lex Fridman's approach to philosophical questions. Assistant B's response, while detailed, provides a more specific answer based on the context of Lex Fridman's discussion on Tesla cars. However, it does not directly answer the question asked by the user about the ethical implications of AI, which is the primary focus of the user's question. Therefore, Assistant A's answer is more relevant to the user's question and is more helpful.\\n\\nVerdict: [[A]]\",\n",
       " 'value': 'A',\n",
       " 'score': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_string_pairs(\n",
    "    prediction=f\"{GemmaOutput['answer']}\",\n",
    "    prediction_b=f\"{Llama3Output['answer']}\",\n",
    "    input={questions[0]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUVATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "\"What does Lex Fridman discuss about the ethical implications of AI?\",\n",
    "\"What insights are shared on human-robot interaction?\",\n",
    "\"What are some technological innovations mentioned in the podcast?\",\n",
    "\"How does Lex Fridman approach philosophical questions in his discussions?\",\n",
    "\"What expertise do guests like Elon Musk bring to the podcast?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langsmith import Client\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.smith import RunEvalConfig, run_on_dataset\n",
    "import numpy as np\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Load API Keys From the .env File\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Document Q&A 2\"\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# LangSmith Quick Start\n",
    "# Load the LangSmith Client and Test Run\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"Q&A data 4\"\n",
    "\n",
    "# Storing inputs in a dataset lets us\n",
    "# run chains and LLMs over a shared set of examples.\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Data for evaluvation\",\n",
    ")\n",
    "\n",
    "for input_prompt in questions:\n",
    "    # Each example must be unique and have inputs defined.\n",
    "    # Outputs are optional\n",
    "    client.create_example(\n",
    "        inputs={\"input\": input_prompt},\n",
    "        outputs=None,\n",
    "        dataset_id=dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'crushing-cloth-55' at:\n",
      "https://smith.langchain.com/o/38ca8262-a246-5483-880a-a4eae38bb4bc/datasets/a882df73-97b2-4922-83f9-c80d0a046681/compare?selectedSessions=4be610ff-9322-4e5a-ba15-9b6170af5ba6\n",
      "\n",
      "View all tests for Dataset Q&A data 4 at:\n",
      "https://smith.langchain.com/o/38ca8262-a246-5483-880a-a4eae38bb4bc/datasets/a882df73-97b2-4922-83f9-c80d0a046681\n",
      "[------------------------------------------------->] 5/5"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'project_name': 'crushing-cloth-55',\n",
       " 'results': {'158a56ab-11ab-4ad1-bb05-b03ad238e8c7': {'input': {'input': 'What expertise do guests like Elon Musk bring to the podcast?'},\n",
       "   'feedback': [EvaluationResult(key='creativity-simplicity-clarity-precision-truthfulness-subtext', score=None, value=None, comment='Error evaluating run f444daae-6325-45b8-a3b3-d0acffeaac65: Could not map run prediction with multiple keys: {\\'input\\': \\'What expertise do guests like Elon Musk bring to the podcast?\\', \\'context\\': [Document(page_content=\"The following is a conversation with Elon Musk. He\\'s the CEO of Tesla, SpaceX, Neuralink, and a cofounder of several other companies. This conversation is part of the Artificial Intelligence podcast. The series includes leading researchers in academia and industry, including CEOs and CTOs of\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"The following is a conversation with Elon Musk. He\\'s the CEO of Tesla, SpaceX, Neuralink, and a cofounder of several other companies. This conversation is part of the Artificial Intelligence podcast. The series includes leading researchers in academia and industry, including CEOs and CTOs of\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"The following is a conversation with Elon Musk. He\\'s the CEO of Tesla, SpaceX, Neuralink, and a cofounder of several other companies. This conversation is part of the Artificial Intelligence podcast. The series includes leading researchers in academia and industry, including CEOs and CTOs of\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"The following is a conversation with Elon Musk. He\\'s the CEO of Tesla, SpaceX, Neuralink, and a cofounder of several other companies. This conversation is part of the Artificial Intelligence podcast. The series includes leading researchers in academia and industry, including CEOs and CTOs of\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'})], \\'answer\\': \\'\\\\n\\\\nAnswer: Guests like Elon Musk bring expertise in the field of technology entrepreneurship and innovation, as they are CEOs and cofounders of multiple tech companies such as Tesla, SpaceX, Neuralink, and others. They also have knowledge and insights regarding the development and application of artificial intelligence in their respective industries.\\'}\\nPlease manually specify a prediction_key', correction=None, evaluator_info={}, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='conciseness', score=None, value=None, comment='Error evaluating run f444daae-6325-45b8-a3b3-d0acffeaac65: Could not map run prediction with multiple keys: {\\'input\\': \\'What expertise do guests like Elon Musk bring to the podcast?\\', \\'context\\': [Document(page_content=\"The following is a conversation with Elon Musk. He\\'s the CEO of Tesla, SpaceX, Neuralink, and a cofounder of several other companies. This conversation is part of the Artificial Intelligence podcast. The series includes leading researchers in academia and industry, including CEOs and CTOs of\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"The following is a conversation with Elon Musk. He\\'s the CEO of Tesla, SpaceX, Neuralink, and a cofounder of several other companies. This conversation is part of the Artificial Intelligence podcast. The series includes leading researchers in academia and industry, including CEOs and CTOs of\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"The following is a conversation with Elon Musk. He\\'s the CEO of Tesla, SpaceX, Neuralink, and a cofounder of several other companies. This conversation is part of the Artificial Intelligence podcast. The series includes leading researchers in academia and industry, including CEOs and CTOs of\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"The following is a conversation with Elon Musk. He\\'s the CEO of Tesla, SpaceX, Neuralink, and a cofounder of several other companies. This conversation is part of the Artificial Intelligence podcast. The series includes leading researchers in academia and industry, including CEOs and CTOs of\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'})], \\'answer\\': \\'\\\\n\\\\nAnswer: Guests like Elon Musk bring expertise in the field of technology entrepreneurship and innovation, as they are CEOs and cofounders of multiple tech companies such as Tesla, SpaceX, Neuralink, and others. They also have knowledge and insights regarding the development and application of artificial intelligence in their respective industries.\\'}\\nPlease manually specify a prediction_key', correction=None, evaluator_info={}, source_run_id=None, target_run_id=None)],\n",
       "   'execution_time': 2.425687,\n",
       "   'run_id': 'f444daae-6325-45b8-a3b3-d0acffeaac65',\n",
       "   'output': {'input': 'What expertise do guests like Elon Musk bring to the podcast?',\n",
       "    'context': [Document(page_content=\"The following is a conversation with Elon Musk. He's the CEO of Tesla, SpaceX, Neuralink, and a cofounder of several other companies. This conversation is part of the Artificial Intelligence podcast. The series includes leading researchers in academia and industry, including CEOs and CTOs of\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'}),\n",
       "     Document(page_content=\"The following is a conversation with Elon Musk. He's the CEO of Tesla, SpaceX, Neuralink, and a cofounder of several other companies. This conversation is part of the Artificial Intelligence podcast. The series includes leading researchers in academia and industry, including CEOs and CTOs of\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'}),\n",
       "     Document(page_content=\"The following is a conversation with Elon Musk. He's the CEO of Tesla, SpaceX, Neuralink, and a cofounder of several other companies. This conversation is part of the Artificial Intelligence podcast. The series includes leading researchers in academia and industry, including CEOs and CTOs of\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'}),\n",
       "     Document(page_content=\"The following is a conversation with Elon Musk. He's the CEO of Tesla, SpaceX, Neuralink, and a cofounder of several other companies. This conversation is part of the Artificial Intelligence podcast. The series includes leading researchers in academia and industry, including CEOs and CTOs of\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'})],\n",
       "    'answer': '\\n\\nAnswer: Guests like Elon Musk bring expertise in the field of technology entrepreneurship and innovation, as they are CEOs and cofounders of multiple tech companies such as Tesla, SpaceX, Neuralink, and others. They also have knowledge and insights regarding the development and application of artificial intelligence in their respective industries.'}},\n",
       "  '82fd7943-0ae2-4b9f-87c0-9d04365d5222': {'input': {'input': 'How does Lex Fridman approach philosophical questions in his discussions?'},\n",
       "   'feedback': [EvaluationResult(key='creativity-simplicity-clarity-precision-truthfulness-subtext', score=None, value=None, comment='Error evaluating run 32cac6d1-f017-4786-b6c1-9f88f36199cc: Could not map run prediction with multiple keys: {\\'input\\': \\'How does Lex Fridman approach philosophical questions in his discussions?\\', \\'context\\': [Document(page_content=\"the philosophy of science, God, ethics, politics, academia, and much, much more. Finally, and perhaps most famously, he\\'s the host of a podcast called Mindscape that you should subscribe to and support on Patreon. Along with the Joe Rogan experience, Sam Harris\\'s Making Sense, and Dan Carlin\\'s\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"the philosophy of science, God, ethics, politics, academia, and much, much more. Finally, and perhaps most famously, he\\'s the host of a podcast called Mindscape that you should subscribe to and support on Patreon. Along with the Joe Rogan experience, Sam Harris\\'s Making Sense, and Dan Carlin\\'s\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"the philosophy of science, God, ethics, politics, academia, and much, much more. Finally, and perhaps most famously, he\\'s the host of a podcast called Mindscape that you should subscribe to and support on Patreon. Along with the Joe Rogan experience, Sam Harris\\'s Making Sense, and Dan Carlin\\'s\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"the philosophy of science, God, ethics, politics, academia, and much, much more. Finally, and perhaps most famously, he\\'s the host of a podcast called Mindscape that you should subscribe to and support on Patreon. Along with the Joe Rogan experience, Sam Harris\\'s Making Sense, and Dan Carlin\\'s\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'})], \\'answer\\': \\'\\\\nAnswer: Lex Fridman approaches philosophical questions in his discussions by discussing various topics such as the philosophy of science, God, ethics, politics, academia, and much more. He is particularly known for hosting a podcast called Mindscape, where he delves into these topics.\\'}\\nPlease manually specify a prediction_key', correction=None, evaluator_info={}, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='conciseness', score=None, value=None, comment='Error evaluating run 32cac6d1-f017-4786-b6c1-9f88f36199cc: Could not map run prediction with multiple keys: {\\'input\\': \\'How does Lex Fridman approach philosophical questions in his discussions?\\', \\'context\\': [Document(page_content=\"the philosophy of science, God, ethics, politics, academia, and much, much more. Finally, and perhaps most famously, he\\'s the host of a podcast called Mindscape that you should subscribe to and support on Patreon. Along with the Joe Rogan experience, Sam Harris\\'s Making Sense, and Dan Carlin\\'s\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"the philosophy of science, God, ethics, politics, academia, and much, much more. Finally, and perhaps most famously, he\\'s the host of a podcast called Mindscape that you should subscribe to and support on Patreon. Along with the Joe Rogan experience, Sam Harris\\'s Making Sense, and Dan Carlin\\'s\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"the philosophy of science, God, ethics, politics, academia, and much, much more. Finally, and perhaps most famously, he\\'s the host of a podcast called Mindscape that you should subscribe to and support on Patreon. Along with the Joe Rogan experience, Sam Harris\\'s Making Sense, and Dan Carlin\\'s\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"the philosophy of science, God, ethics, politics, academia, and much, much more. Finally, and perhaps most famously, he\\'s the host of a podcast called Mindscape that you should subscribe to and support on Patreon. Along with the Joe Rogan experience, Sam Harris\\'s Making Sense, and Dan Carlin\\'s\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'})], \\'answer\\': \\'\\\\nAnswer: Lex Fridman approaches philosophical questions in his discussions by discussing various topics such as the philosophy of science, God, ethics, politics, academia, and much more. He is particularly known for hosting a podcast called Mindscape, where he delves into these topics.\\'}\\nPlease manually specify a prediction_key', correction=None, evaluator_info={}, source_run_id=None, target_run_id=None)],\n",
       "   'execution_time': 2.915732,\n",
       "   'run_id': '32cac6d1-f017-4786-b6c1-9f88f36199cc',\n",
       "   'output': {'input': 'How does Lex Fridman approach philosophical questions in his discussions?',\n",
       "    'context': [Document(page_content=\"the philosophy of science, God, ethics, politics, academia, and much, much more. Finally, and perhaps most famously, he's the host of a podcast called Mindscape that you should subscribe to and support on Patreon. Along with the Joe Rogan experience, Sam Harris's Making Sense, and Dan Carlin's\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'}),\n",
       "     Document(page_content=\"the philosophy of science, God, ethics, politics, academia, and much, much more. Finally, and perhaps most famously, he's the host of a podcast called Mindscape that you should subscribe to and support on Patreon. Along with the Joe Rogan experience, Sam Harris's Making Sense, and Dan Carlin's\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'}),\n",
       "     Document(page_content=\"the philosophy of science, God, ethics, politics, academia, and much, much more. Finally, and perhaps most famously, he's the host of a podcast called Mindscape that you should subscribe to and support on Patreon. Along with the Joe Rogan experience, Sam Harris's Making Sense, and Dan Carlin's\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'}),\n",
       "     Document(page_content=\"the philosophy of science, God, ethics, politics, academia, and much, much more. Finally, and perhaps most famously, he's the host of a podcast called Mindscape that you should subscribe to and support on Patreon. Along with the Joe Rogan experience, Sam Harris's Making Sense, and Dan Carlin's\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'})],\n",
       "    'answer': '\\nAnswer: Lex Fridman approaches philosophical questions in his discussions by discussing various topics such as the philosophy of science, God, ethics, politics, academia, and much more. He is particularly known for hosting a podcast called Mindscape, where he delves into these topics.'}},\n",
       "  'c1360514-fb3a-40f8-8df5-9056ab07ac7c': {'input': {'input': 'What are some technological innovations mentioned in the podcast?'},\n",
       "   'feedback': [EvaluationResult(key='creativity-simplicity-clarity-precision-truthfulness-subtext', score=None, value=None, comment='Error evaluating run 719adbd5-c376-4056-ab21-ae5c2cd2d7dc: Could not map run prediction with multiple keys: {\\'input\\': \\'What are some technological innovations mentioned in the podcast?\\', \\'context\\': [Document(page_content=\"product here. And so I just took the plunge right then and there and said, this is something I know I can commit 10 years to. It\\'s the probably the greatest applied AI problem of our generation. And if it works, it\\'s going to be both a huge business and therefore like, probably the most positive\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"product here. And so I just took the plunge right then and there and said, this is something I know I can commit 10 years to. It\\'s the probably the greatest applied AI problem of our generation. And if it works, it\\'s going to be both a huge business and therefore like, probably the most positive\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"product here. And so I just took the plunge right then and there and said, this is something I know I can commit 10 years to. It\\'s the probably the greatest applied AI problem of our generation. And if it works, it\\'s going to be both a huge business and therefore like, probably the most positive\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"product here. And so I just took the plunge right then and there and said, this is something I know I can commit 10 years to. It\\'s the probably the greatest applied AI problem of our generation. And if it works, it\\'s going to be both a huge business and therefore like, probably the most positive\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'})], \\'answer\\': \\'\\\\nAnswer: The context does not mention a podcast. However, it does mention the \"probably the greatest applied AI problem of our generation\" which is a technological innovation in the field of Artificial Intelligence (AI).\\'}\\nPlease manually specify a prediction_key', correction=None, evaluator_info={}, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='conciseness', score=None, value=None, comment='Error evaluating run 719adbd5-c376-4056-ab21-ae5c2cd2d7dc: Could not map run prediction with multiple keys: {\\'input\\': \\'What are some technological innovations mentioned in the podcast?\\', \\'context\\': [Document(page_content=\"product here. And so I just took the plunge right then and there and said, this is something I know I can commit 10 years to. It\\'s the probably the greatest applied AI problem of our generation. And if it works, it\\'s going to be both a huge business and therefore like, probably the most positive\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"product here. And so I just took the plunge right then and there and said, this is something I know I can commit 10 years to. It\\'s the probably the greatest applied AI problem of our generation. And if it works, it\\'s going to be both a huge business and therefore like, probably the most positive\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"product here. And so I just took the plunge right then and there and said, this is something I know I can commit 10 years to. It\\'s the probably the greatest applied AI problem of our generation. And if it works, it\\'s going to be both a huge business and therefore like, probably the most positive\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"product here. And so I just took the plunge right then and there and said, this is something I know I can commit 10 years to. It\\'s the probably the greatest applied AI problem of our generation. And if it works, it\\'s going to be both a huge business and therefore like, probably the most positive\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'})], \\'answer\\': \\'\\\\nAnswer: The context does not mention a podcast. However, it does mention the \"probably the greatest applied AI problem of our generation\" which is a technological innovation in the field of Artificial Intelligence (AI).\\'}\\nPlease manually specify a prediction_key', correction=None, evaluator_info={}, source_run_id=None, target_run_id=None)],\n",
       "   'execution_time': 2.91123,\n",
       "   'run_id': '719adbd5-c376-4056-ab21-ae5c2cd2d7dc',\n",
       "   'output': {'input': 'What are some technological innovations mentioned in the podcast?',\n",
       "    'context': [Document(page_content=\"product here. And so I just took the plunge right then and there and said, this is something I know I can commit 10 years to. It's the probably the greatest applied AI problem of our generation. And if it works, it's going to be both a huge business and therefore like, probably the most positive\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'}),\n",
       "     Document(page_content=\"product here. And so I just took the plunge right then and there and said, this is something I know I can commit 10 years to. It's the probably the greatest applied AI problem of our generation. And if it works, it's going to be both a huge business and therefore like, probably the most positive\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'}),\n",
       "     Document(page_content=\"product here. And so I just took the plunge right then and there and said, this is something I know I can commit 10 years to. It's the probably the greatest applied AI problem of our generation. And if it works, it's going to be both a huge business and therefore like, probably the most positive\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'}),\n",
       "     Document(page_content=\"product here. And so I just took the plunge right then and there and said, this is something I know I can commit 10 years to. It's the probably the greatest applied AI problem of our generation. And if it works, it's going to be both a huge business and therefore like, probably the most positive\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'})],\n",
       "    'answer': '\\nAnswer: The context does not mention a podcast. However, it does mention the \"probably the greatest applied AI problem of our generation\" which is a technological innovation in the field of Artificial Intelligence (AI).'}},\n",
       "  'b336bbb9-f731-42d8-83ef-721b5f9faca6': {'input': {'input': 'What insights are shared on human-robot interaction?'},\n",
       "   'feedback': [EvaluationResult(key='creativity-simplicity-clarity-precision-truthfulness-subtext', score=None, value=None, comment='Error evaluating run a971be83-e73e-4637-b7af-e01150aaf5ab: Could not map run prediction with multiple keys: {\\'input\\': \\'What insights are shared on human-robot interaction?\\', \\'context\\': [Document(page_content=\"for both you and I have been identified as both potentially being robots. If you have to prove to the world that you are indeed human, how would you do it? I can understand thinking that I\\'m a robot. It\\'s the flip side of the Turing test, I think. Yeah, yeah, the prove your human test.\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"for both you and I have been identified as both potentially being robots. If you have to prove to the world that you are indeed human, how would you do it? I can understand thinking that I\\'m a robot. It\\'s the flip side of the Turing test, I think. Yeah, yeah, the prove your human test.\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"for both you and I have been identified as both potentially being robots. If you have to prove to the world that you are indeed human, how would you do it? I can understand thinking that I\\'m a robot. It\\'s the flip side of the Turing test, I think. Yeah, yeah, the prove your human test.\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"for both you and I have been identified as both potentially being robots. If you have to prove to the world that you are indeed human, how would you do it? I can understand thinking that I\\'m a robot. It\\'s the flip side of the Turing test, I think. Yeah, yeah, the prove your human test.\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'})], \\'answer\\': \\'\\\\nAnswer: The context suggests that the Turing Test, a test to determine whether or not a machine can exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human, is often used to determine if a machine is human-like. In this case, the reverse is being considered, the \"prove your human test,\" implying a concern about being mistaken for a robot. However, no specific insights on human-robot interaction are directly shared in the provided context.\\'}\\nPlease manually specify a prediction_key', correction=None, evaluator_info={}, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='conciseness', score=None, value=None, comment='Error evaluating run a971be83-e73e-4637-b7af-e01150aaf5ab: Could not map run prediction with multiple keys: {\\'input\\': \\'What insights are shared on human-robot interaction?\\', \\'context\\': [Document(page_content=\"for both you and I have been identified as both potentially being robots. If you have to prove to the world that you are indeed human, how would you do it? I can understand thinking that I\\'m a robot. It\\'s the flip side of the Turing test, I think. Yeah, yeah, the prove your human test.\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"for both you and I have been identified as both potentially being robots. If you have to prove to the world that you are indeed human, how would you do it? I can understand thinking that I\\'m a robot. It\\'s the flip side of the Turing test, I think. Yeah, yeah, the prove your human test.\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"for both you and I have been identified as both potentially being robots. If you have to prove to the world that you are indeed human, how would you do it? I can understand thinking that I\\'m a robot. It\\'s the flip side of the Turing test, I think. Yeah, yeah, the prove your human test.\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\"for both you and I have been identified as both potentially being robots. If you have to prove to the world that you are indeed human, how would you do it? I can understand thinking that I\\'m a robot. It\\'s the flip side of the Turing test, I think. Yeah, yeah, the prove your human test.\", metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'})], \\'answer\\': \\'\\\\nAnswer: The context suggests that the Turing Test, a test to determine whether or not a machine can exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human, is often used to determine if a machine is human-like. In this case, the reverse is being considered, the \"prove your human test,\" implying a concern about being mistaken for a robot. However, no specific insights on human-robot interaction are directly shared in the provided context.\\'}\\nPlease manually specify a prediction_key', correction=None, evaluator_info={}, source_run_id=None, target_run_id=None)],\n",
       "   'execution_time': 2.608745,\n",
       "   'run_id': 'a971be83-e73e-4637-b7af-e01150aaf5ab',\n",
       "   'output': {'input': 'What insights are shared on human-robot interaction?',\n",
       "    'context': [Document(page_content=\"for both you and I have been identified as both potentially being robots. If you have to prove to the world that you are indeed human, how would you do it? I can understand thinking that I'm a robot. It's the flip side of the Turing test, I think. Yeah, yeah, the prove your human test.\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'}),\n",
       "     Document(page_content=\"for both you and I have been identified as both potentially being robots. If you have to prove to the world that you are indeed human, how would you do it? I can understand thinking that I'm a robot. It's the flip side of the Turing test, I think. Yeah, yeah, the prove your human test.\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'}),\n",
       "     Document(page_content=\"for both you and I have been identified as both potentially being robots. If you have to prove to the world that you are indeed human, how would you do it? I can understand thinking that I'm a robot. It's the flip side of the Turing test, I think. Yeah, yeah, the prove your human test.\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'}),\n",
       "     Document(page_content=\"for both you and I have been identified as both potentially being robots. If you have to prove to the world that you are indeed human, how would you do it? I can understand thinking that I'm a robot. It's the flip side of the Turing test, I think. Yeah, yeah, the prove your human test.\", metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'})],\n",
       "    'answer': '\\nAnswer: The context suggests that the Turing Test, a test to determine whether or not a machine can exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human, is often used to determine if a machine is human-like. In this case, the reverse is being considered, the \"prove your human test,\" implying a concern about being mistaken for a robot. However, no specific insights on human-robot interaction are directly shared in the provided context.'}},\n",
       "  '86f4fd6b-23b3-4adc-8285-201b59cc4478': {'input': {'input': 'What does Lex Fridman discuss about the ethical implications of AI?'},\n",
       "   'feedback': [EvaluationResult(key='creativity-simplicity-clarity-precision-truthfulness-subtext', score=None, value=None, comment='Error evaluating run 0ec7ca9f-bde7-4bc3-b0aa-4999d3e16c23: Could not map run prediction with multiple keys: {\\'input\\': \\'What does Lex Fridman discuss about the ethical implications of AI?\\', \\'context\\': [Document(page_content=\\'and applications of AI, and so he has a unique perspective on global innovation and the future of AI that I think is important to listen to and think about. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube and iTunes, support it on Patreon, or simply connect with\\', metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\\'and applications of AI, and so he has a unique perspective on global innovation and the future of AI that I think is important to listen to and think about. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube and iTunes, support it on Patreon, or simply connect with\\', metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\\'and applications of AI, and so he has a unique perspective on global innovation and the future of AI that I think is important to listen to and think about. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube and iTunes, support it on Patreon, or simply connect with\\', metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\\'and applications of AI, and so he has a unique perspective on global innovation and the future of AI that I think is important to listen to and think about. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube and iTunes, support it on Patreon, or simply connect with\\', metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'})], \\'answer\\': \"\\\\n\\\\nAnswer: Based on the provided context, Lex Fridman discusses about his unique perspective on global innovation and the future of AI, but there\\'s no explicit mention of him discussing the ethical implications of AI. However, as a researcher and practitioner in the field of AI, it\\'s reasonable to infer that he might touch upon ethical aspects of AI in his discussions, as it is a critical and ongoing topic in the field. But without specific context, it\\'s not possible to confirm that he discusses the ethical implications of AI in this particular podcast.\"}\\nPlease manually specify a prediction_key', correction=None, evaluator_info={}, source_run_id=None, target_run_id=None),\n",
       "    EvaluationResult(key='conciseness', score=None, value=None, comment='Error evaluating run 0ec7ca9f-bde7-4bc3-b0aa-4999d3e16c23: Could not map run prediction with multiple keys: {\\'input\\': \\'What does Lex Fridman discuss about the ethical implications of AI?\\', \\'context\\': [Document(page_content=\\'and applications of AI, and so he has a unique perspective on global innovation and the future of AI that I think is important to listen to and think about. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube and iTunes, support it on Patreon, or simply connect with\\', metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\\'and applications of AI, and so he has a unique perspective on global innovation and the future of AI that I think is important to listen to and think about. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube and iTunes, support it on Patreon, or simply connect with\\', metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\\'and applications of AI, and so he has a unique perspective on global innovation and the future of AI that I think is important to listen to and think about. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube and iTunes, support it on Patreon, or simply connect with\\', metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'}), Document(page_content=\\'and applications of AI, and so he has a unique perspective on global innovation and the future of AI that I think is important to listen to and think about. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube and iTunes, support it on Patreon, or simply connect with\\', metadata={\\'source\\': \\'docs\\\\\\\\Lex\\\\\\\\podcastdata_dataset.csv\\'})], \\'answer\\': \"\\\\n\\\\nAnswer: Based on the provided context, Lex Fridman discusses about his unique perspective on global innovation and the future of AI, but there\\'s no explicit mention of him discussing the ethical implications of AI. However, as a researcher and practitioner in the field of AI, it\\'s reasonable to infer that he might touch upon ethical aspects of AI in his discussions, as it is a critical and ongoing topic in the field. But without specific context, it\\'s not possible to confirm that he discusses the ethical implications of AI in this particular podcast.\"}\\nPlease manually specify a prediction_key', correction=None, evaluator_info={}, source_run_id=None, target_run_id=None)],\n",
       "   'execution_time': 2.870944,\n",
       "   'run_id': '0ec7ca9f-bde7-4bc3-b0aa-4999d3e16c23',\n",
       "   'output': {'input': 'What does Lex Fridman discuss about the ethical implications of AI?',\n",
       "    'context': [Document(page_content='and applications of AI, and so he has a unique perspective on global innovation and the future of AI that I think is important to listen to and think about. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube and iTunes, support it on Patreon, or simply connect with', metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'}),\n",
       "     Document(page_content='and applications of AI, and so he has a unique perspective on global innovation and the future of AI that I think is important to listen to and think about. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube and iTunes, support it on Patreon, or simply connect with', metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'}),\n",
       "     Document(page_content='and applications of AI, and so he has a unique perspective on global innovation and the future of AI that I think is important to listen to and think about. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube and iTunes, support it on Patreon, or simply connect with', metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'}),\n",
       "     Document(page_content='and applications of AI, and so he has a unique perspective on global innovation and the future of AI that I think is important to listen to and think about. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube and iTunes, support it on Patreon, or simply connect with', metadata={'source': 'docs\\\\Lex\\\\podcastdata_dataset.csv'})],\n",
       "    'answer': \"\\n\\nAnswer: Based on the provided context, Lex Fridman discusses about his unique perspective on global innovation and the future of AI, but there's no explicit mention of him discussing the ethical implications of AI. However, as a researcher and practitioner in the field of AI, it's reasonable to infer that he might touch upon ethical aspects of AI in his discussions, as it is a critical and ongoing topic in the field. But without specific context, it's not possible to confirm that he discusses the ethical implications of AI in this particular podcast.\"}}},\n",
       " 'aggregate_metrics': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 3. Evaluate Datasets Without Labels\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    evaluators=[\n",
    "        # You can define an arbitrary criterion as a key: value pair in the criteria dict\n",
    "        RunEvalConfig.Criteria(\n",
    "            {\"creativity\": \"Is this submission creative, imaginative, or novel?\",\n",
    "                \"simplicity\": \"Is the language straightforward and unpretentious?\",\n",
    "                \"clarity\": \"Are the sentences clear and easy to understand?\",\n",
    "                \"precision\": \"Is the writing precise, with no unnecessary words or details?\",\n",
    "                \"truthfulness\": \"Does the writing feel honest and sincere?\",\n",
    "                \"subtext\": \"Does the writing suggest deeper meanings or themes?\"}\n",
    "        ),\n",
    "        # We provide some simple default criteria like \"conciseness\" you can use as well\n",
    "        RunEvalConfig.Criteria(\"conciseness\")\n",
    "    ],\n",
    "    eval_llm=MistralLLM,\n",
    ")\n",
    "\n",
    "run_on_dataset(\n",
    "    client=client,\n",
    "    dataset_name=\"Q&A data 4\",\n",
    "    llm_or_chain_factory=RetrievalChainMistralLLM,\n",
    "    evaluation=evaluation_config,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see Evaluvation at : [Langsmith](https://smith.langchain.com/public/b07c7bda-41e1-45fd-9a7c-3c9bebf40ac4/d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
